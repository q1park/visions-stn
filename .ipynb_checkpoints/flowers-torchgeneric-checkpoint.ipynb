{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowers\n",
    "\n",
    "https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datadir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c804d76ce0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                transforms.Normalize([0.5, 0.5, 0.5], \n\u001b[1;32m     19\u001b[0m                                                                     [0.5, 0.5, 0.5])])}\n\u001b[0;32m---> 20\u001b[0;31m dirs = {\"train\": datadir + \"train\", \n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatadir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \"test\": datadir + \"test\"}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datadir' is not defined"
     ]
    }
   ],
   "source": [
    "basedir = '/home/q1park/visions/data/'\n",
    "subclasses = [0, 10, 20]\n",
    "\n",
    "datatransforms = {\"train\": transforms.Compose([transforms.RandomRotation(30),\n",
    "                                               transforms.Resize(120),\n",
    "                                                transforms.CenterCrop(120),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize([0.5, 0.5, 0.5], \n",
    "                                                                     [0.5, 0.5, 0.5])]),\n",
    "                   \"valid\": transforms.Compose([transforms.Resize(120),\n",
    "                                                transforms.CenterCrop(120),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize([0.5, 0.5, 0.5], \n",
    "                                                                     [0.5, 0.5, 0.5])]),\n",
    "                   \"test\": transforms.Compose([transforms.Resize(120),\n",
    "                                               transforms.CenterCrop(120),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize([0.5, 0.5, 0.5], \n",
    "                                                                    [0.5, 0.5, 0.5])])}\n",
    "dirs = {\"train\": datadir + \"train\", \n",
    "        \"valid\": datadir + \"valid\", \n",
    "        \"test\": datadir + \"test\"}\n",
    "\n",
    "imgsets = {x: datasets.ImageFolder(dirs[x], transform=datatransforms[x]) \\\n",
    "           for x in [\"train\", \"valid\", \"test\"]}\n",
    "\n",
    "imgfilters = {x: [imgsets[x][i] for i in range(len(imgsets[x])) \\\n",
    "                  if imgsets[x][i][1] in subclasses ] \\\n",
    "              for x in [\"train\", \"valid\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "\n",
    "imgsubsets = {x: imgfilters[x] for x in [\"train\", \"valid\", \"test\"]}\n",
    "loaders = {x: torch.utils.data.DataLoader(imgsubsets[x], batch_size=batchsize, shuffle=True) \\\n",
    "           for x in [\"train\", \"valid\", \"test\"]}\n",
    "sizes = {x: len(imgsubsets[x]) \\\n",
    "         for x in [\"train\", \"valid\", \"test\"]}\n",
    "\n",
    "print(sizes[\"train\"], sizes[\"test\"], sizes[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datarunner = iter(loaders[\"train\"]);\n",
    "\n",
    "images, labels = next(datarunner)\n",
    "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
    "\n",
    "for ii in range(4):\n",
    "    ax = axes[ii]\n",
    "    helper.imshow(images[ii], ax=ax, normalize=False)\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_checkpoint(model, check_name):\n",
    "    checkpoint = {'state_dict': model.state_dict()}\n",
    "    torch.save(checkpoint, check_name)\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = Network()\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        \n",
    "        # pool after conv reduces image size 120 > 60 > 30 > 15\n",
    "        self.fc1 = nn.Linear(64*15*15, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 102)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(-1, 64*15*15)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    \n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "\n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "\n",
    "                train_losses.append(running_loss/len(trainloader))\n",
    "                test_losses.append(test_loss/len(testloader))\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                running_loss = 0\n",
    "                \n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, loaders[\"train\"], loaders[\"test\"], criterion, optimizer, epochs=40, print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmark = 'checkpoint_'+'1'+'.pth'\n",
    "\n",
    "make_checkpoint(model, checkmark)\n",
    "\n",
    "model_fresh = load_checkpoint(checkmark)\n",
    "print(model_fresh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
